{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from embedding import general_embedding, update_embedding\n",
    "\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model file at  ./models/ggml-gpt4all-j-v1.3-groovy.bin\n",
      "gptj_model_load: loading model from './models/ggml-gpt4all-j-v1.3-groovy.bin' - please wait ...\n",
      "gptj_model_load: n_vocab = 50400\n",
      "gptj_model_load: n_ctx   = 2048\n",
      "gptj_model_load: n_embd  = 4096\n",
      "gptj_model_load: n_head  = 16\n",
      "gptj_model_load: n_layer = 28\n",
      "gptj_model_load: n_rot   = 64\n",
      "gptj_model_load: f16     = 2\n",
      "gptj_model_load: ggml ctx size = 5401.45 MB\n",
      "gptj_model_load: kv self size  =  896.00 MB\n",
      "gptj_model_load: ................................... done\n",
      "gptj_model_load: model size =  3609.38 MB / num tensors = 285\n"
     ]
    }
   ],
   "source": [
    "# 定义大语言模型LLMs\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "gpt4all_path = './models/ggml-gpt4all-j-v1.3-groovy.bin' \n",
    "llm = GPT4All(model=gpt4all_path, callback_manager=callback_manager, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from ./models/ggml-model-q4_0.bin\n",
      "llama.cpp: can't use mmap because tensors are not aligned; convert to new format to avoid this\n",
      "llama_model_load_internal: format     = 'ggml' (old version with low tokenizer quality and no mmap support)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 512\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 2 (mostly Q4_0)\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size = 4113748.20 KB\n",
      "llama_model_load_internal: mem required  = 5809.33 MB (+ 2052.00 MB per state)\n",
      "...................................................................................................\n",
      ".\n",
      "llama_init_from_file: kv self size  =  512.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# 定义嵌入式模型embedding\n",
    "# embeddings = GPT4AllEmbeddings()\n",
    "\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "llama_path = './models/ggml-model-q4_0.bin' \n",
    "embeddings = LlamaCppEmbeddings(model_path=llama_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成datastores\n",
    "base_folder_path = './docs/base'\n",
    "update_folder_path = './docs/update'\n",
    "updata = True\n",
    "if not os.path.exists(\"datastores\"):\n",
    "    general_embedding(base_folder_path)\n",
    "elif os.listdir(update_folder_path):\n",
    "    update_embedding(update_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_search(query, index):\n",
    "    matched_docs = index.similarity_search(query, k=3) \n",
    "    sources = []\n",
    "    for doc in matched_docs:\n",
    "        sources.append(\n",
    "            {\n",
    "                \"page_content\": doc.page_content,\n",
    "                \"metadata\": doc.metadata,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return matched_docs, sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载datastores\n",
    "index = FAISS.load_local(\"datastores\", embeddings)\n",
    "\n",
    "# 保持连续对话\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 样例\n",
    "template = \"\"\"Please use the following context to answer questions.\n",
    "Context: {context}\n",
    "------------------------\n",
    "Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# 定义链\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, memory=memory)\n",
    "\n",
    "# while True:\n",
    "#     # query\n",
    "#     question = input(\"Your question: \")\n",
    "\n",
    "#     # 检索，得到上下文信息context\n",
    "#     matched_docs, sources = similarity_search(question, index)\n",
    "#     context = \"\\n\".join([doc.page_content for doc in matched_docs])\n",
    "\n",
    "#     llm_chain.prompt = llm_chain.prompt.partial(context=context)\n",
    "\n",
    "#     # 将检索结果和问题一起输入LLM，输出结果\n",
    "#     print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "chat = ConversationalRetrievalChain.from_llm(llm, retriever=index.as_retriever(), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   723.71 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
      "llama_print_timings: prompt eval time =   989.71 ms /    11 tokens (   89.97 ms per token)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
      "llama_print_timings:       total time =   995.34 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The following is a list of different task decomposition methods used in industrial control systems, along with their advantages and disadvantages:\n",
      "1. Hierarchical Task Analysis (HTA) - This method involves breaking down complex tasks into smaller sub-tasks that can be performed by individual workers or teams. It helps to identify bottlenecks and optimize the workflow for better performance. However, it may require a significant amount of time and resources to implement HTA in large industrial systems with many processes running simultaneously.\n",
      "2. Workflow Management Systems (WMS) - These software tools help manage complex workflows by providing real-time visibility into tasks' progress, enabling workers to make adjustments as needed. WMS can be integrated within PLC applications for improved task management and performance optimization. However, they may require significant investment in hardware or licensing fees depending on the complexity of their features.\n",
      "3. Task Assignment Algorithms (TAA) - These algorithms are used by industrial control systems to assign tasks among workers based on various factors such as availability, skillset, workload capacity, etc. TAA can help optimize task assignments and improve overall system performance in real-time scenarios where worker schedules may change frequently or dynamically.\n",
      "4. Task Scheduling Algorithms ("
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" The following is a list of different task decomposition methods used in industrial control systems, along with their advantages and disadvantages:\\n1. Hierarchical Task Analysis (HTA) - This method involves breaking down complex tasks into smaller sub-tasks that can be performed by individual workers or teams. It helps to identify bottlenecks and optimize the workflow for better performance. However, it may require a significant amount of time and resources to implement HTA in large industrial systems with many processes running simultaneously.\\n2. Workflow Management Systems (WMS) - These software tools help manage complex workflows by providing real-time visibility into tasks' progress, enabling workers to make adjustments as needed. WMS can be integrated within PLC applications for improved task management and performance optimization. However, they may require significant investment in hardware or licensing fees depending on the complexity of their features.\\n3. Task Assignment Algorithms (TAA) - These algorithms are used by industrial control systems to assign tasks among workers based on various factors such as availability, skillset, workload capacity, etc. TAA can help optimize task assignments and improve overall system performance in real-time scenarios where worker schedules may change frequently or dynamically.\\n4. Task Scheduling Algorithms (\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chat({\"question\": \"What are the approaches to Task Decomposition?\"})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What is the main contribution of this paper to task decomposition and scheduling algorithms in industrial control systems, if any?"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   723.71 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
      "llama_print_timings: prompt eval time =  2254.53 ms /    27 tokens (   83.50 ms per token)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per run)\n",
      "llama_print_timings:       total time =  2269.18 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The main contribution of this paper on PLC programming for plant maintenance tasks is a detailed explanation of how to use specialized language tools like SFMPLS. It also provides an overview of the benefits of using these programs compared to traditional PC-based software and highlights some potential challenges in implementing them effectively, such as managing multiple languages or dealing with limited resources. Overall, this paper contributes valuable insights into PLC programming for plant maintenance tasks that can be useful for those working on industrial control systems who need a more efficient way to manage their workflows."
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The main contribution of this paper on PLC programming for plant maintenance tasks is a detailed explanation of how to use specialized language tools like SFMPLS. It also provides an overview of the benefits of using these programs compared to traditional PC-based software and highlights some potential challenges in implementing them effectively, such as managing multiple languages or dealing with limited resources. Overall, this paper contributes valuable insights into PLC programming for plant maintenance tasks that can be useful for those working on industrial control systems who need a more efficient way to manage their workflows.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "result = chat({\"question\": \"How does the Reflexion paper handle it?\"})\n",
    "result['answer']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
